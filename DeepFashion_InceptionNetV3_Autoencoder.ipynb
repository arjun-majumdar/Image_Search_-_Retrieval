{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be944c99-bd39-47e6-ae5b-ae955f974dfe",
   "metadata": {},
   "source": [
    "# _DeepFashion_ Autoencoder using Inception NetV3 extracted features\n",
    "\n",
    "Inception NetV3 outputs (None, 2048) volume. To further reduce it to 90-dimensions, an autoencoder is used on the extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c2fbec-9124-450b-8cc1-632b12094e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Input, InputLayer\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import RandomNormal, Constant\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle, os, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951511ec-5879-4254-bab9-f61f235d8c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f358a24-6035-4614-94cc-4e0aa345c4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3b1da0-4de8-4dd0-bacb-b8c4fd7a577a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of GPUs available = 1\n"
     ]
    }
   ],
   "source": [
    "num_gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "print(f\"number of GPUs available = {num_gpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0e6d35-2195-4a0b-933a-940f642b9742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4223f0a0-221d-44be-8d76-97e86f2736f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pickled Python3 list containing 2048-d extracted feature representation per image-\n",
    "features_list = pickle.load(open(\"DeepFashion_features_inceptionnetv3.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7caa6a6d-7f83-4c17-a1f1-9888d175cba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289229, 2048)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert from Python3 list to numpy array-\n",
    "features_list_np = np.asarray(features_list)\n",
    "\n",
    "features_list_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb9622d3-0202-4067-9341-00d4473ba130",
   "metadata": {},
   "outputs": [],
   "source": [
    "del features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da227725-4f37-4ea7-bcf3-148b77e9e89e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad0d7e8b-8a8b-43ee-a6a4-b16dbd0efcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pickled Python3 list containing abolute path and filenames-\n",
    "filenames_list = pickle.load(open(\"DeepFashion_filenames_inceptionnetv3.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7437a0b3-0b02-424d-91ff-674346298c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289229, 289229)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list_np.shape[0], len(filenames_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eb1e8a6-66d5-4036-a9b6-4547ca11564a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/img/1981_Graphic_Ringer_Tee/img_00000002.jpg'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the absolute path contains Google colab path-\n",
    "filenames_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42572f90-6a4f-4bac-a8e0-ec1b1a7234b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bdcec8-6bbc-4d8a-a7d1-8be459c39d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc1d36e7-2f64-46a0-ad7f-fc18922bcb72",
   "metadata": {},
   "source": [
    "### Autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b39209e-d16f-4bcf-9bd7-d2c276652e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = Sequential([\n",
    "            InputLayer(input_shape = (2048, )),\n",
    "            Dense(\n",
    "                units = 1024, activation = 'relu',\n",
    "                kernel_initializer = tf.keras.initializers.glorot_normal(),\n",
    "                use_bias = True, bias_initializer = RandomNormal(mean = 0.0, stddev = 0.05)\n",
    "                 ),\n",
    "            Dense(\n",
    "                units = 512, activation = 'relu',\n",
    "                kernel_initializer = tf.keras.initializers.glorot_normal(),\n",
    "                use_bias = True, bias_initializer = RandomNormal(mean = 0.0, stddev = 0.05)\n",
    "                 ),\n",
    "            Dense(\n",
    "                units = 256, activation = 'relu',\n",
    "                kernel_initializer = tf.keras.initializers.glorot_normal(),\n",
    "                use_bias = True, bias_initializer = RandomNormal(mean = 0.0, stddev = 0.05)\n",
    "                 ),\n",
    "            Dense(\n",
    "                units = 90, activation = 'relu',\n",
    "                kernel_initializer = tf.keras.initializers.glorot_normal(),\n",
    "                use_bias = True, bias_initializer = RandomNormal(mean = 0.0, stddev = 0.05)\n",
    "                 ),\n",
    "        ])\n",
    "    \n",
    "        self.decoder = Sequential([\n",
    "            Dense(\n",
    "                units = 256, activation = 'relu',\n",
    "                kernel_initializer = tf.keras.initializers.glorot_normal(),\n",
    "                use_bias = True, bias_initializer = RandomNormal(mean = 0.0, stddev = 0.05)\n",
    "                 ),\n",
    "            Dense(\n",
    "                units = 512, activation = 'relu',\n",
    "                kernel_initializer = tf.keras.initializers.glorot_normal(),\n",
    "                use_bias = True, bias_initializer = RandomNormal(mean = 0.0, stddev = 0.05)\n",
    "                 ),\n",
    "            Dense(\n",
    "                units = 1024, activation = 'relu',\n",
    "                kernel_initializer = tf.keras.initializers.glorot_normal(),\n",
    "                use_bias = True, bias_initializer = RandomNormal(mean = 0.0, stddev = 0.05)\n",
    "                 ),\n",
    "            Dense(\n",
    "                units = 2048, activation = 'sigmoid',\n",
    "                use_bias = True, bias_initializer = RandomNormal(mean = 0.0, stddev = 0.05)\n",
    "                 ),\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8d7244-3525-4c14-b64f-82628ad8473c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f23ee31d-2da0-4609-a275-8c13657227d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and build defined autoencoder-\n",
    "model = Autoencoder()\n",
    "model.build(input_shape = (None, 2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "073a050c-a51b-4d69-82e3-0c870e8f0d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_4 (Sequential)    (None, 90)                2777434   \n",
      "_________________________________________________________________\n",
      "sequential_5 (Sequential)    (None, 2048)              2779392   \n",
      "=================================================================\n",
      "Total params: 5,556,826\n",
      "Trainable params: 5,556,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9dd9173-4dbc-425c-9e0b-7d24de60470b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: (2048, 1024) has 2097152 wts\n",
      "layer: (1024,) has 1024 wts\n",
      "layer: (1024, 512) has 524288 wts\n",
      "layer: (512,) has 512 wts\n",
      "layer: (512, 256) has 131072 wts\n",
      "layer: (256,) has 256 wts\n",
      "layer: (256, 90) has 23040 wts\n",
      "layer: (90,) has 90 wts\n",
      "layer: (90, 256) has 23040 wts\n",
      "layer: (256,) has 256 wts\n",
      "layer: (256, 512) has 131072 wts\n",
      "layer: (512,) has 512 wts\n",
      "layer: (512, 1024) has 524288 wts\n",
      "layer: (1024,) has 1024 wts\n",
      "layer: (1024, 2048) has 2097152 wts\n",
      "layer: (2048,) has 2048 wts\n"
     ]
    }
   ],
   "source": [
    "tot_params = 0\n",
    "\n",
    "for layer in model.trainable_weights:\n",
    "    loc_param = tf.math.count_nonzero(layer, axis = None).numpy()\n",
    "    tot_params += loc_param\n",
    "    print(f\"layer: {layer.shape} has {loc_param} wts\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04e76f34-927a-4181-b8ad-858a160f8e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters in Autoencoder: 5556826\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of trainable parameters in Autoencoder: {tot_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1076cd7e-ef07-443c-96ad-32d25627f5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d6cc3ca-4db7-41e0-b74e-3989b8e6346b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2048)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "x = features_list_np[:5, :]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27e512f0-ee49-4741-9451-00cee473be41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 90])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_encoded = model.encoder(x)\n",
    "x_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9faa86cb-1c24-4193-9dd8-7e974f7aaf4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 2048])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reconstructed = model.decoder(x_encoded)\n",
    "x_reconstructed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5250ae77-dcf6-4886-ad76-ba5b67da97c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b424870-273e-489b-8f9b-dddb5199d58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9e1cae7-bb31-479b-a00b-778895487161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model-\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "    loss = tf.keras.losses.MeanSquaredError()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a265093-cb04-4628-ad7b-b1f06a212af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping criterion-\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss', min_delta = 0.001, patience = 3, verbose = 0,\n",
    "    mode = 'auto', baseline = None, restore_best_weights = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59df31b-ac4b-436d-b454-48ea2f1bb24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train autoencoder-\n",
    "history = model.fit(\n",
    "    x = features_list_np, y = features_list_np,\n",
    "    epochs = 30, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c649e8-a154-43fe-adbe-c271a01590f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a41f7-12bc-4575-a3dd-c914a15dd78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057e6de-1952-4154-a3f5-7de507464d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
